# Redpanda Statefulset TLS PLayground

This project demonstrates using Server Name Indication (SNI) to route
TLS connections without TLS termination. It includes a demonstration
app, written in Python, that provides a basic TCP echo service that
self-identifies on connect. A prescribed Helm-based installation of
Redpanda demonstrates how to take the same approach and apply it to a
Redpanda cluster in k8s.

> But...why?

This approach allows you to expose a single ingress for a stateful
service in k8s while allowing clients to specific which instance
(e.g. which broker) they intend to talk to via TCP. Instead of using
NodePorts or a 1:1 broker:LoadBalancer approach, this simplifies the
architecture for external clients at the expense of some networking
overhead.

How much overhead is yet to be determined ðŸ˜‰

## Pre-reqs
- Docker
- Helm
- Kubectl
- either:
  - k3d (for local k3s orchestration)
  - GCP access (for GKE orchestration)
  - AWS access (...todo)

> This was developed and tested all on an arm64 Debian 12 host. YMMV.

## Optional Env Vars
- `RP_DOMAIN` - defaults to "sni-demo.redpanda-labs.com", used for the
  advertised addresses of the external kafka api listeners.
- `CLUSTER_NAME` - name of the k3d cluster, defaults to "sni-test"

## Deploying
Assuming you're testing this locally with k3s, you can do the
following.

1. Spin up a k3s cluster using k3d. (Skip this if using GKE, etc.)

```
$ ./k3d.sh      # spin up the k3s cluster
```

2. Deploy Cert-Manager.

> You may need to wait a bit for k3s to be ready.

```
$ kubectl apply -f k8s/00-cert-manager.yaml   # install cert-manager
$ kubectl apply -f k8s/01-cert-issuers.yaml   # deploy issuers
```

3. Deploy the sample Echo application.

It's a simple Python TCP Echo app that uses TLS, with certificates
generated by cert-manager. To avoid having to build and push a
customer Docker image, we'll just stick the Python source into a
ConfigMap. (YOLO!)

```
$ kubectl create namespace echo
$ kubectl create configmap echo-src -n echo --from-file=echo/app.py
$ kubectl apply -f k8s/02-statefulset.yaml
```

4. Deploy Redpanda

You can skip this if you just want to use the test app (i.e. "echo"),
but included is a shell script that wraps deploying Redpanda via Helm
with the correct settings for leveraging the Traefik ingress. It will
test that the cluster is formed by creating a sample topic.

```
$ ./redpanda.sh
```

> If you want to customize the external domain used, either modify the
> shell script or set the environment variable `RP_DOMAIN` to
> something you want to use.

5. Deploy the Traefik ingress application.

```
$ kubectl apply -f k8s/03-traefik.yaml
```

6. Expose the Traefik Ingress

> If you're using GKE, etc. Use the appropriate LoadBalancer config in
> one of the subdirectories.

In the case of k3d, we'll use a `NodePort`.

```
$ kubectl apply -f k3d/04-nodeport.yaml
```

## Testing the Echo App

### Using the OpenSSL Client Container

The included `Makefile` will build a Docker image with OpenSSL and
some scripting to help you quickly test SNI routing within the Docker
network (i.e. this doesn't use the NodePort, but does talk to the
LoadBalancer k3d creates that the NodePort exposes).

```
$ make build
```

Once built, you can run an instance using the command below. You
should end up in a Docker instance *outside* the k3s cluster. The
entrypoint shell script will update `/etc/hosts` for the echo service.

```
$ make run-client
Updating /etc/hosts:
192.168.48.6 echo-0.echo-svc.echo.svc.cluster.local
192.168.48.6 echo-1.echo-svc.echo.svc.cluster.local
192.168.48.6 echo-svc.echo.svc.cluster.local

-----------------------------------------------------------------
You can now connect to one of the statefulset pods using openssl.

For example, to force connection to echo-1:

# openssl s_client -servername echo-1.echo-svc.echo.svc.cluster.local echo-svc.echo.svc.cluster.local:30888

TODO: pull in the self-signed root CA for verification

/ #
```

The "echo" application should greet each connection with its FQDN and
then just echo back any lines you send it.

### And now with Redpanda!

1. When you ran `./redpanda.sh`, it should have copied the root
   certificate for the external listeners to a local file:
   `redpanda-ca.crt`. Make sure it's there.

2. Update your `/etc/hosts` to contain the Redpanda brokers exposed
   via the NodePort that sends traffic to the traefik ingress using
   the external domain (`RP_DOMAIN`):

```
# echo "
127.0.0.1  redpanda-0.sni-demo.redpanda-labs.com
127.0.0.1  redpanda-1.sni-demo.redpanda-labs.com
127.0.0.1  redpanda-2.sni-demo.redpanda-labs.com
" >> /etc/hosts
```

3. Configure an `rpk` profile for accessing the cluster:

> Note: for sake of brevity, we're just using the `redpanda-0` node.

```
$ rpk profile create sni-demo \
    --set brokers=redpanda-0.sni-demo.redpanda-labs.com:9094 \
    --set tls.enabled=true \
    --set tls.ca="$(realpath ./redpanda-ca.crt)" \
    --set admin.hosts=redpanda-0.sni-demo.redpanda-labs.com \
    --set admin.tls.enabled=true \
    --set admin.tls.ca="$(realpath ./redpanda-ca.crt)"
```

4. Check the cluster info via the Admin API to see the external Kafka
   advertised addresses.

```
$ rpk cluster info
CLUSTER
=======
redpanda.ea5ffb96-9533-4a65-a3fc-efa88bd252c6

BROKERS
=======
ID    HOST                                   PORT
0*    redpanda-0.sni-demo.redpanda-labs.com  9094
1     redpanda-1.sni-demo.redpanda-labs.com  9094
2     redpanda-2.sni-demo.redpanda-labs.com  9094

TOPICS
======
NAME           PARTITIONS  REPLICAS
_schemas       1           3
example-topic  1           3
solo           1           1
```

5. List topics.

```
$ rpk topic list
NAME           PARTITIONS  REPLICAS
_schemas       1           3
example-topic  1           3
```

6. Create a topic with no replication and a single partition.

```
$ rpk topic create solo -r 1
TOPIC  STATUS
solo   OK
```

7. Find which broker hosts the `solo` topic.

```
$ rpk topic list --detailed
_schemas, 1 partitions, 3 replicas
      PARTITION  LEADER  EPOCH  REPLICAS
      0          0       1      [0 1 2]

example-topic, 1 partitions, 3 replicas
      PARTITION  LEADER  EPOCH  REPLICAS
      0          1       1      [0 1 2]

solo, 1 partitions, 1 replicas
      PARTITION  LEADER  EPOCH  REPLICAS
      0          1       1      [1]
```

In the above example, it's on node 2. Let's show we can produce and
consume to it which providing just the `redpanda-0` broker as the
discovery broker.

8. Produce a simple message.

```
$ echo "SNI is Fun" | rpk topic produce solo
Produced to partition 0 at offset 0 with timestamp 1692044323438.
```

9. Consume a message using the other node as the broker seed (in this
   case, `redpanda-2`).

```
$ rpk topic consume solo --num 1 \
    --brokers redpanda-2.sni-demo.redpanda-labs.com.:9094
{
  "topic": "solo",
  "value": "SNI is Fun",
  "timestamp": 1692044323438,
  "partition": 0,
  "offset": 0
}
```

Still don't believe it after reading the above? Here's the consuming
again but with verbose mode enabled in rpk:

```
$ rpk topic consume solo -v --num 1 --brokers redpanda-2.sni-demo.redpanda-labs.com.:9094 --tls-enabled --tls-truststore redpanda-ca.crt
16:23:30.800 [INFO] immediate metadata update triggered; why: querying metadata for consumer initialization
16:23:30.800 [DEBUG] opening connection to broker; addr: redpanda-2.sni-demo.redpanda-labs.com.:9094, broker: seed 0
16:23:30.806 [DEBUG] connection opened to broker; addr: redpanda-2.sni-demo.redpanda-labs.com.:9094, broker: seed 0
16:23:30.806 [DEBUG] issuing api versions request; broker: seed 0, version: 3
16:23:30.806 [DEBUG] wrote ApiVersions v3; broker: seed 0, bytes_written: 31, write_wait: 78.084Âµs, time_to_write: 23.333Âµs, err: <nil>
16:23:30.806 [DEBUG] read ApiVersions v3; broker: seed 0, bytes_read: 296, read_wait: 74.542Âµs, time_to_read: 664.003Âµs, err: <nil>
16:23:30.807 [DEBUG] connection initialized successfully; addr: redpanda-2.sni-demo.redpanda-labs.com.:9094, broker: seed 0
16:23:30.807 [DEBUG] wrote Metadata v7; broker: seed 0, bytes_written: 28, write_wait: 6.642153ms, time_to_write: 30.5Âµs, err: <nil>
16:23:30.807 [DEBUG] read Metadata v7; broker: seed 0, bytes_read: 295, read_wait: 31.208Âµs, time_to_read: 753.629Âµs, err: <nil>
16:23:30.808 [INFO] assigning partitions; why: new assignments from direct consumer, how: assigning everything new, keeping current assignment, input: solo[0{-2 e-1 ce0}]
16:23:30.808 [DEBUG] assign requires loading offsets
16:23:30.808 [DEBUG] offsets to load broker; broker: 1, load: {map[solo:map[0:{-2 e-1 ce1}]] map[]}
16:23:30.808 [DEBUG] opening connection to broker; addr: redpanda-1.sni-demo.redpanda-labs.com.:9094, broker: 1
16:23:30.811 [DEBUG] connection opened to broker; addr: redpanda-1.sni-demo.redpanda-labs.com.:9094, broker: 1
16:23:30.811 [DEBUG] issuing api versions request; broker: 1, version: 3
16:23:30.811 [DEBUG] wrote ApiVersions v3; broker: 1, bytes_written: 31, write_wait: 35.75Âµs, time_to_write: 30.417Âµs, err: <nil>
16:23:30.812 [DEBUG] read ApiVersions v3; broker: 1, bytes_read: 296, read_wait: 20.75Âµs, time_to_read: 598.419Âµs, err: <nil>
16:23:30.812 [DEBUG] connection initialized successfully; addr: redpanda-1.sni-demo.redpanda-labs.com.:9094, broker: 1
16:23:30.812 [DEBUG] wrote ListOffsets v4; broker: 1, bytes_written: 52, write_wait: 4.208267ms, time_to_write: 37.875Âµs, err: <nil>
16:23:30.813 [DEBUG] read ListOffsets v4; broker: 1, bytes_read: 52, read_wait: 34.667Âµs, time_to_read: 365.335Âµs, err: <nil>
16:23:30.813 [DEBUG] handled list results; broker: 1, using: map[solo:map[0:{0 1}]], reloading: map[]
16:23:30.813 [DEBUG] opening connection to broker; addr: redpanda-1.sni-demo.redpanda-labs.com.:9094, broker: 1
16:23:30.815 [DEBUG] connection opened to broker; addr: redpanda-1.sni-demo.redpanda-labs.com.:9094, broker: 1
16:23:30.815 [DEBUG] connection initialized successfully; addr: redpanda-1.sni-demo.redpanda-labs.com.:9094, broker: 1
16:23:30.815 [DEBUG] wrote Fetch v11; broker: 1, bytes_written: 90, write_wait: 2.232384ms, time_to_write: 8.25Âµs, err: <nil>
16:23:30.815 [DEBUG] read Fetch v11; broker: 1, bytes_read: 152, read_wait: 26.208Âµs, time_to_read: 503.294Âµs, err: <nil>
{
  "topic": "solo",
  "value": "SNI is Fun",
  "timestamp": 1692044323438,
  "partition": 0,
  "offset": 0
}
```
